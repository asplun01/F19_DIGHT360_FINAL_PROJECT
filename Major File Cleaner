import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))


def get_wordnet_pos(treebank_tag):
'''Replace the tag with a command the lemmatizer can understand'''
    if treebank_tag.startswith('J'):
        return 'a'
    elif treebank_tag.startswith('V'):
        return 'v'
    elif treebank_tag.startswith('N'):
        return 'n'
    elif treebank_tag.startswith('R'):
        return 'r'
    else:
        return 'n'


lemmatizer = WordNetLemmatizer()
majors = []
with open('BYUMajors.txt') as f:
    for line in f:
        majors.append(line.rstrip())

for major in majors:
    words = []
    taggedWords = []
    oldFile = str(major) + ".html"
    newFile = str(major) + ".html"
    with open(oldFile, "r") as f:
        data = f.read()
    with open(newFile, "w") as f:
        words.extend(nltk.word_tokenize(data))
        lowerCase = [str(word).lower() for word in words]
        noStopWords = [word for word in lowerCase if word not in stop_words]
        taggedWords.extend(nltk.pos_tag(noStopWords))
        lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in taggedWords]
        f.write(' '.join(lemmatized))
